---
title: "Take-Home_Ex1"
author: "Roger"
editor: visual
format: html
execute: 
  warning: false
  message: false
---

# 1. Overview

Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world's accessible freshwater.

Developing countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.

To address the issue of providing clean and sustainable water supply to the rural community, a global [Water Point Data Exchange (WPdx)](https://www.waterpointdata.org/about/) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on [WPDx Data Standard](https://www.waterpointdata.org/wp-content/uploads/2021/04/WPDx_Data_Standard.pdf).

## 1.1 Setting the scene

The process of creating regions is called [regionalisation](https://www.researchgate.net/publication/28153673_Supervised_Regionalization_Methods_A_Survey/link/0fcfd5094046b13d35000000/download). A regionalisation is a special kind of clustering where the objective is to group observations which are similar in their statistical attributes, but also in their spatial location. In this sense, regionalization embeds the same logic as standard clustering techniques, but also applies a series of geographical constraints. Often, these constraints relate to connectivity: two candidates can only be grouped together in the same region if there exists a path from one member to another member that never leaves the region. These paths often model the spatial relationships in the data, such as contiguity or proximity. However, connectivity does not always need to hold for all regions, and in certain contexts it makes sense to relax connectivity or to impose different types of geographic constraints.

## 1.2 Objectives

In this study, we will regionalise Nigeria by using, but not limited to the following measures:

-   Total number of functional water points

-   Total number of nonfunctional water points

-   Percentage of functional water points

-   Percentage of non-functional water points

-   Percentage of main water point technology (i.e. Hand Pump)

-   Percentage of usage capacity (i.e. \< 1000, \>=1000)

-   Percentage of rural water points

In the code chunk below, p_load(0 of pacman package is used to load the following R packages into R environment:

-   Spatial data handling

    -   **sf**, **rgdal** and **spdep**

-   Attribute data handling

    -   **tidyverse**, especially **readr**, **ggplot2** and **dplyr**

```{r}
#also have readexcel for excel spreadsheets
```

-   Choropleth mapping

    -   **tmap**

-   Multivariate data visualisation and analysis

    -   **coorplot**, **ggpubr**, and **heatmaply**

-   Cluster analysis

    -   **cluster**

    -   **ClustGeo**

```{r}
pacman::p_load(rgdal, spdep, tmap, sf, ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, tidyverse)
```

# 2. Data Acquisition

## 2.1 Importing the geospatial data

For this study, two geospatial data will be used:

### 2.1.1 Importing water point geospatial data

-   The water point geospatial data will be downloaded from [WPdx Global Data Repositories](https://www.waterpointdata.org/access-data/), specifically the WPdx+ data set will be used. In the code chunk below, we will import the shapefile as simple features data table into R environment using st_read() of sf package. filter() of dplyr will be used to extract water point records of Nigeria.

```{r}
#| eval: false

wp <- st_read(dsn = "data",
              layer= "geo_export",
              crs = 4326) %>%
  filter(clean_coun == "Nigeria")
```

Next, write_rds() of readr package is used to save the extracted sf data table (i.e. wp) into an output file in rds data format, and saved in the data sub-folder.

```{r}
#| eval: false

write_rds(wp, "data/wp_nga.rds")
```

### 2.1.2 Importing Nigeria LGA boundary geospatial data

-   The Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data will be the second data set used in this study. The data is downloaded from [geoBoundaries](https://www.geoboundaries.org/). In the code chunk below, we will import the Nigeria LGA boundary shapefile data as a simple features data table into R environment using st_read() of sf package.

```{r}
#| eval: false

nga <- st_read(dsn = "data", 
                 layer = "nga_polnda_adm2_1m_salb",
                 crs = 4326) 
```

## 2.2 Data Wrangling

### 2.2.1 Recoding NA values into string

In the code chunk below, replace_na() of tidyr package is used to recode all the NA values in *status_cle* field into "Unknown".

```{r}
#| eval: false

wp_nga <- read_rds("data/wp_nga.rds") %>%
  mutate(status_cle = replace_na(status_cle, "Unknown"))
```

### 2.2.2 Exploratory data analysis (EDA)

In the code chunks below, freq() of funModeling package is used to display the distribution of *status_cle* field in *wp_nga*.

```{r}
#| eval: false

freq(data = wp_nga,
     input = "status_cle")
```

### 2.2.3 Extracting functional water point

In the code chunk below, filter() of dplyr is used to select functional water points.

```{r}
#| eval: false

wpt_functional <- wp_nga %>%
  filter(status_cle %in%
           c("Functional",
             "Functional but not in use",
             "Functional but needs repair"))
```

```{r}
#| eval: false

freq(data= wpt_functional,
     input = "status_cle")
```

### 2.2.4 Extracting non-functional water point

In the code chunk below, filter() of dplyr is used to select non-functional water points.

```{r}
#| eval: false

wpt_nonfunctional <- wp_nga %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned",
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

```{r}
#| eval: false

freq(data = wpt_nonfunctional,
     input = "status_cle")
```

### 2.2.5 Extracting water point with unknown class

In the code chunk below, filter() of dplyr is used to select water points with unknown status.

```{r}
#| eval: false

wpt_unknown <- wp_nga %>%
  filter(status_cle == "Unknown")
```

### 2.2.6 Performing point-in-polygon count

In the code chunk below, st_intersects() of sf is used to identify water points located in each Nigerian province; *lengths()* of Base R is used to calculate numbers of water points that fall inside each province, and mutate() of dplyr package is used to derive four fields, namely: (a) total wpt, (b) wpt functional, (c) wpt non-functional, (d) wpt unknown.

```{r}
#| eval: false

nga_wp <- nga %>% 
  mutate(`total wpt` = lengths(
    st_intersects(nga, wp_nga))) %>%
  mutate(`wpt functional` = lengths(
    st_intersects(nga, wpt_functional))) %>%
  mutate(`wpt non-functional` = lengths(
    st_intersects(nga, wpt_nonfunctional))) %>%
  mutate(`wpt unknown` = lengths(
    st_intersects(nga, wpt_unknown)))
```

### 2.2.7 Saving the analytical data table

In the code chunk below, mutate() of dplyr package is used to drive two fields, namely pct_functional and pct non-functional. To keep the file size small, select() of dplyr is used to retain only fields 3,4,9,10,18,19,20,21,22 and 23.

```{r}
#| eval: false

nga_wp <- nga_wp %>% 
  mutate(`pct_functional` = `wpt functional` / `total wpt`) %>%
  mutate(`pct_non-functional` = `wpt non-functional`/ `total wpt`) #%>%
#  select(3:4, 9:10, 18:23)
```

Next, write_rds() of readr package is used to save the extracted sf data table into an output file in rds data format, and saved in the data sub-folder.

```{r}
#| eval: false

write_rds(nga_wp, "data/nga_wp.rds")
```

### 2.2.8 Assigning EPSG code to the simple feature data frame

One of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.

Using the code chunk below, we will examine the current coordinate system of `nga_wp` simple feature data frame by using *st_crs()* of *sf* package.

```{r}
#| eval: false

st_crs(nga_wp)
```

*Observation: Although `the nga_wp`data frame is projected in WGS84 but when we read until the end of the print, it indicates that the EPSG is 4326. This is a wrong EPSG code because the correct EPSG code for WGS84 should be either 26391, 26392, or 26303*

Using the code below, *st_transform()* of **sf** package is used to assign the correct EPSG code (which we will select 26391) to `nga_wp` data frame.

```{r}
#| eval: false

nga_wp26391 <- st_transform(nga_wp,
                            crs = 26391)
```

Using the code chunk below, we will check the CRS again.

```{r}
#| eval: false

st_crs(nga_wp26391)
```

Next, write_rds() of readr package is used to save the extracted sf data table into an output file in rds data format, and saved in the data sub-folder.

```{r}
#| eval: false

write_rds(nga_wp26391, "data/nga_wp26391.rds")
```

# 3. Visualising the Spatial Distribution of Water Points

In the code chunk below, qtm() of tmap package is used to plot the thematic maps depicting Nigeria waterpoints quickly, while tmap_arrange() is used to create multiple stand-alone maps .

```{r}
#| fig-width: 14
#| fig-height: 12

nga_wp <- read_rds("data/nga_wp.rds")
total <- qtm(nga_wp, "total wpt")
wp_functional <- qtm(nga_wp, "wpt functional")
wp_nonfunctional <- qtm(nga_wp, "wpt non-functional")
unknown <- qtm(nga_wp, "wpt unknown")

tmap_arrange(total, wp_functional, wp_nonfunctional, unknown, asp=1, ncol=2)
```

# 4. Computing Contiguity Spatial Weights

Building a neighbours list based on regions with contiguous boundaries

## 4.1 Computing (QUEEN) contiguity based neighbours

In the code chunk below, poly2nb() of spdep package is used to compute the Queen contiguity weight matrix.

```{r}
wm_q <- poly2nb(nga_wp, queen = TRUE)
summary(wm_q)
```

*Observation: The summary report above shows that there are 773 area units in Nigeria. The most connected area unit has 13 neighbours, while 2 area units only have one neighbour each.*

## 4.2 Visualising contiguity weights

A connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs.

To get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation \[\[\]\] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[1]])
```

We will do the same for latitude with one key difference, in that we access the second value per centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[2]])
```

Now that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

Checking the first few observations to see if things are formatted correctly

```{r}
head(coords)
```

### 4.2.1 Plotting Queen contiguity based neighbours map

```{r}
plot(nga_wp$geometry, border = "lightgrey")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
```

# 5. Computing Distance Based Neighbours

The function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in **km** will be calculated with the WGS84 reference ellipsoid.

## 5.1 Determining the cut-off distance

We will first determine the upper limit for distance band by using the steps below:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [*knearneigh()*](https://r-spatial.github.io/spdep/reference/knearneigh.html) of spdep.

-   Convert the knn object returned by *knearneigh()* into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [*knn2nb()*](https://r-spatial.github.io/spdep/reference/knn2nb.html).

-   Return the length of neighbour relationship edges by using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

-   Remove the list structure of the returned object by using [**unlist()**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

*Observation: The summary report shows that the largest first neighbour distance is 71.769km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.*

## 5.2 Computing fixed distance weight matrix

Using the code chunk below, we will compute the distance weight matrix using dnearneigh() of spdep.

```{r}
wm_d72 <- dnearneigh(coords, 0, 72, longlat = TRUE)
wm_d72
```

*Observation: The summary report above shows that on average, each area unit is nearest in distance to another 23 area units.*

### 5.2.1 Plotting fixed distance weight matrix

Using the code chunk below, we will plot the distance weight matrix.

```{r}
#| fig-width: 14
#| fig-height: 12

par(mfrow=c(1,2))
plot(nga_wp$geometry, border = "lightgrey")
plot(k1, coords, add=TRUE, col="red", length = 0.08)
plot(nga_wp$geometry, border = "lightgrey")
plot(wm_d72, coords, add=TRUE)
```

### 5.2.2 Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours while the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

Using the code chunk below, we will control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry. We will set the number of neighbours at 8.

```{r}
knn8 <- knn2nb(knearneigh(coords, k=8))
knn8
```

#### 

#### 5.2.2.1 Plotting distance based neighbours

Using the code chunk below, we can plot the weight matrix.

```{r}
plot(nga_wp$geometry, border = "lightgrey")
plot(knn8, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

### 5.2.3 Row-standarised weights matrix

Next, we will assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style="W"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this method summaries the neighbors' values, one drawback is that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this study, we'll be using style="W" option.

```{r}
rswm_q <- nb2listw(wm_q, style = "W", zero.policy = TRUE)
rswm_q
```

# 6. Application of spatial weight matrix

## 6.1 Spatial lag with row-standardised weights

We will be computing the average neighbour non-functional wpt value for each polygon. Using the code chunk below, we append the spatially lag non-functional waterpoint values onto the Nigeria sf data frame using left_join().

```{r}

lag.list <- list(nga_wp$ADM2_CODE, lag.listw(rswm_q, nga_wp$`wpt non-functional`) )
lag.res <- as.data.frame(lag.list)
colnames(lag.res) <- c("ADM2_CODE", "lag wpt non-functional")
nga_wp <- left_join(nga_wp, lag.res)
```

*Observation: In the course of this study, i had attempted to join compute the list using ADM2_Name (which was similar to the "County" in the Hunan dataset). However, I kept running into errors, and eventually i realised that the names of the villages (e.g. ADM2_Name) were not unique. However, the ADM2_Code were unique! It reflected that different villages could share the same name while being at very different places.*

Using the code chunk below, we will now plot both the non-functional wpt and the spatial lag non-functional wpt for comparison.

```{r}
nft <- qtm(nga_wp, "wpt non-functional")
lag_nft <- qtm(nga_wp, "lag wpt non-functional")

tmap_arrange(nft, lag_nft, asp=1, ncol=2)
```

## 6.2 Spatial lag as a sum of neighbouring values

Next, we will calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.

We will start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, to manipulate the neighbors structure. This applies a function across each value in the neighbors structure.

```{r}

b_weights <- lapply(wm_q, function(x) 0*x + 1)
b_weights2 <- nb2listw(wm_q, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With the weights assigned, we will now use lag.listw of spdep to compute a lag variable from our weight and non-functional wpt.

```{r}
lag_sum <- list(nga_wp$ADM2_CODE, lag.listw(b_weights2, nga_wp$`wpt non-functional`))
lag.res <- as.data.frame(lag_sum)
colnames(lag.res) <- c("ADM2_CODE", "lag_sum wpt non-functional")
```

Using the code chunk below, we will append the lag_sum wpt non functional to the nga_wp sf data frame

```{r}
nga_wp <-left_join(nga_wp, lag.res)
```

Using the code chunk below, we can now plot both the non-functional water points and spatial lag non-functional water points for comparison.

```{r}
nft <- qtm(nga_wp, "wpt non-functional")
lag_sum_nft <- qtm(nga_wp, "lag_sum wpt non-functional")
tmap_arrange(nft, lag_sum_nft, asp=1, ncol=2)
```

# 

# 7. Global Spatial Autocorrelation

## 7.1 Moran's I

Using the code chunk below, we will perform the Moran's I statistics testing by using moran.test() of spdep.

```{r}
moran.test(nga_wp$`wpt non-functional`,
           listw = rswm_q,
           zero.policy = TRUE,
           na.action = na.omit)
```

*Observation: As p-value is \<0.025, we can conclude that it is statistically significant that the distribution of non-functional waterpoints are randomly distributed.*

### 7.1.1 Computing Monte Carlo Moran's I

Using the code chunk below, we will perform permutation test for Moran's I statistic by using moran.mc() of spdep. A total of 1,000 simulations will be performed.

```{r}
set.seed(1234)
bperm = moran.mc(nga_wp$`wpt non-functional`,
                 listw = rswm_q,
                 nsim=999,
                 zero.policy = TRUE,
                 na.action = na.omit)
bperm
```

*Observation: From the output above, as p-value is \< 0.025, it supports the earlier statistical conclusion that the distribution of the non-functional water points are indeed randomly distributed.*

### 7.1.2 Visualising Monte Carlo Moran's I

In the code chunk below, we will examine the simulated Moran's I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram, using hist() and abline() of R Graphics.

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res,
     freq=TRUE,
     breaks =20,
     xlab="Simulated Moran's I")
abline(v=0, col="red")
```

# 8. Cluster and Outlier Analysis

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. In this instance, we will be studying non-functional water points among census tracts in the Nigerian city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

## 

## 8.1 Computing local Moran's I

Using the code chunk below, we will compute local Moran's I, using the localmoran() function of spdep. It computes *Ii* values, given a set of *zi* values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

```{r}
fips <- order(nga_wp$ADM2_CODE)
localMI <- localmoran(nga_wp$`wpt non-functional`, rswm_q)
head(localMI)
```

The output above from localmoran() function returns a matrix of values whose columns are:

-   Ii: the local Moran's I statistics

-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis

-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis

-   Z.Ii:the standard deviate of local moran statistic

-   Pr(): the p-value of local moran statistic

### 8.1.1 Mapping the local Moran's I

Using the code chunk below, we will append the local Moran's I dataframe (i.e. localMI) onto Nigeria SpatialPolygonDataFrame. The output SpatialPolygonDataFrame is called nga.localMI.

```{r}
nga.localMI <- cbind(nga_wp, localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

### 8.1.2 Mapping both local Moran's I values and p-values

Using the code chunk below, we will:

-   Plot the local Moran's I values using choropleth mapping functions of **tmap** package.

-   Produce a choropleth map of Moran's I p-values by using functions of tmap package.

```{r}
localMI.map <- tm_shape(nga.localMI)+
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "Local Moran's I  Statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(nga.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "Local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

## 8.2 Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

### 8.2.1 Plotting Moran scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

Using the code chunks below, we will plot the Moran scatterplot of non-functional waterpoints by using moran.plot() of spdep.

```{r}
nci <- moran.plot(nga_wp$`wpt non-functional`, rswm_q,
                  labels=as.character(nga_wp$HRname), 
                  xlab="Non Functional Water Points ", 
                  ylab="Spatially Lag Non Functional Water Points")
```

*Observation: The output is split into 4 quadrants. The top right corner belongs to areas that have high non-functional water points and are surrounded by other areas that have the average level of non-functional water points.*

### 8.2.2 Plotting Moran scatterplot with standardised variable

First we will use scale() to center and scale the variable. Centering is done by subtracting the mean from the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations. as.vector() will be added to the end to make sure that the data type we get out of this is a vector, that map neatly into the dataframe.

```{r}
nga_wp_Z <- scale(nga_wp$`wpt non-functional`) %>%
  as.vector
```

Using the code chunk below, we will plot the Moran scatterplot again.

```{r}
nci2 <- moran.plot(nga_wp_Z, rswm_q,
                   labels=as.character(nga_wp$HRname),
                   xlab="z-Non-Functional Water Points", 
                   ylab="Spatially Lag z-Non-Functional Water Points")
```

### 8.3 Preparing LISA map classes

Using the code chunks below, we will prepare the LISA cluster map.

```{r}
quadrant <- vector(mode="numeric", length=nrow(localMI))
```

Next, we will derive the spatially lagged variable of interest (i.e. non functional water points) and centers the spatially lagged variable around its mean.

```{r}
nga_wp$`lag wpt non-functional` <- lag.listw(rswm_q, nga_wp$`wpt non-functional`)
DV <- nga_wp$`lag wpt non-functional` - mean(nga_wp$`lag wpt non-functional`)
```

This is followed by centering the local Moran's I around the mean.

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])
```

Next, we will set up a statistical significance level for the local Moran.

```{r}
signif <- 0.05
```

```{r}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4 
```

Lastly, we place the non-significant Moran in the category "0".

```{r}
quadrant[localMI[,5]>signif] <- 0
```

## 8.4 Plotting LISA map

Using the code chunks below, we can now build the LISA map.

```{r}
nga.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(nga.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

For effective interpretation, it is better to plot both the local MOran's I values map and its corresponding p-values next to each other.

Using the code chunks below, we will create such a visualisation.

```{r}
nft <- qtm(nga_wp, "wpt non-functional")

nga.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(nga.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(nft, LISAmap, 
             asp=1, ncol=2)
```

Using the code chunks below, we will also include the local Moran's I map and p-value map for easier comparison.

```{r}
tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

# 9. Hot Spot and Cold Spot Area Analysis

Besides detecting cluster and outliers, localised spatial statistics can also be used to detect hot spot and/or cold spot areas.

## 9.1 Getis and Ord's G-Statistics

An alternative spatial statistics to detect spatial anomalies is the Getis and Ord's G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

### 9.1.1 Gi statistics using fixed distance

Using the code chunk below, we will first convert the nb object (i.e. wm_d72) into a spatial weights object using nb2listw() of spdep. Then we will compute the local spatial G statistics for each neighbour using localG() of spdep.

```{r}
wm72_lw <- nb2listw(wm_d72, style = "B")
gi.fixed <- localG(nga_wp$`wpt non-functional`, wm72_lw)
gi.fixed
```

Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

Using the code chunk below, we will next join the Gi values to their corresponding Nigeria sf data frame. First, it converts the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join nga_wp and gi.fixed matrix to produce a new SpatialPolygonDataFrame called nga.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().

```{r}
nga.gi <- cbind(nga_wp, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

### 9.1.2 Mapping Gi values with fixed distance weights

Using the code chunk below, we wil map the Gi values derived using fixed distance weight matrix.

```{r}
nft <- qtm(nga_wp, "wpt non-functional")

Gimap <-tm_shape(nga.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "Local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(nft, Gimap, asp=1, ncol=2)
```

### 9.1.3 Gi statistics using adaptive distance

Using the code chunk below, we will compute the Gi values by using an adaptive distance weight matrix. We will first convert the nb object (i.e. knn8) into a spatial weights object using nb2listw() of spdep. Then we will compute the local spatial G statistics for each neighbour using localG() of spdep.

```{r}
knn8_lw <- nb2listw(knn8, style = "B")
gi.adaptive <- localG(nga_wp$`wpt non-functional`, knn8_lw)
nga.gi <- cbind(nga_wp, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

### 9.1.4 Mappin Gi values with adaptive distance weights

Using the code chunks below, we will visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.

```{r}
nft<- qtm(nga_wp, "wpt non-functional")

Gimap <- tm_shape(nga.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "Local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(nft, 
             Gimap, 
             asp=1, 
             ncol=2)
```

# 
