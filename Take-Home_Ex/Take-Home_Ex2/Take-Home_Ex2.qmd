---
title: "Take-Home_Ex2"
author: "Roger"
editor: visual
format: html
execute: 
  warning: false
  message: false
---

# 1. Overview

Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world's accessible freshwater.

Developing countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.

To address the issue of providing clean and sustainable water supply to the rural community, a global [Water Point Data Exchange (WPdx)](https://www.waterpointdata.org/about/) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on [WPDx Data Standard](https://www.waterpointdata.org/wp-content/uploads/2021/04/WPDx_Data_Standard.pdf).

## 1.1 Setting the scene

The process of creating regions is called [regionalisation](https://www.researchgate.net/publication/28153673_Supervised_Regionalization_Methods_A_Survey/link/0fcfd5094046b13d35000000/download). A regionalisation is a special kind of clustering where the objective is to group observations which are similar in their statistical attributes, but also in their spatial location. In this sense, regionalization embeds the same logic as standard clustering techniques, but also applies a series of geographical constraints. Often, these constraints relate to connectivity: two candidates can only be grouped together in the same region if there exists a path from one member to another member that never leaves the region. These paths often model the spatial relationships in the data, such as contiguity or proximity. However, connectivity does not always need to hold for all regions, and in certain contexts it makes sense to relax connectivity or to impose different types of geographic constraints.

## 1.2 Objectives

In this study, we will regionalise Nigeria by using, but not limited to the following measures:

-   Total number of functional water points

-   Total number of nonfunctional water points

-   Percentage of functional water points

-   Percentage of non-functional water points

-   Percentage of main water point technology (i.e. Hand Pump)

-   Percentage of usage capacity (i.e. \< 1000, \>=1000)

-   Percentage of rural water points

In the code chunk below, p_load(0 of pacman package is used to load the following R packages into R environment:

-   Spatial data handling

    -   **sf**, **rgdal** and **spdep**

-   Attribute data handling

    -   **tidyverse**, especially **readr**, **ggplot2** and **dplyr**

-   Choropleth mapping

    -   **tmap**

-   Exploratory data analysis, data preparation and model performance

    -   funModeling

-   Multivariate data visualisation and analysis

    -   **coorplot**, **ggpubr**, and **heatmaply**

-   Cluster analysis

    -   **cluster**

    -   **ClustGeo**

```{r}
pacman::p_load(rgdal, spdep, tmap, sf, ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, tidyverse, funModeling, ClustGeo, GGally)
```

# 2. Data Acquisition

## 2.1 Importing the geospatial data

For this study, two geospatial data will be used:

### 2.1.1 Importing water point geospatial data

-   The water point geospatial data will be downloaded from [WPdx Global Data Repositories](https://www.waterpointdata.org/access-data/), specifically the WPdx+ data set will be used. In the code chunk below, we will import the shapefile as simple features data table into R environment using st_read() of sf package. filter() of dplyr will be used to extract water point records of Nigeria.s

```{r}
#| eval: false

wp <- st_read(dsn = "data2",
              layer= "geo_export",
              crs = 4326) %>%
  filter(clean_coun == "Nigeria")
```

Next, write_rds() of readr package is used to save the extracted sf data table (i.e. wp) into an output file in rds data format, and saved in the data sub-folder.

```{r}
#| eval: false

write_rds(wp, "data2/wp_nga.rds")
```

### 2.1.2 Importing Nigeria LGA boundary geospatial data

-   The Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data will be the second data set used in this study. The data is downloaded from [geoBoundaries](https://www.geoboundaries.org/). In the code chunk below, we will import the Nigeria LGA boundary shapefile data as a simple features data table into R environment using st_read() of sf package.

```{r}
#| eval: false

nga <- st_read(dsn = "data2", 
                 layer = "nga_polnda_adm2_1m_salb",
                 crs = 4326)
```

![](data2/screenshot%201.jpg)

## 2.2 Data Wrangling

### 2.2.1 Removing duplicated names (if any)

Using the code chunk below, we will first order our data frame by alphabetical order based on the HRname. We will then use the duplicated function of Base R to retrieve all the HRnames that have duplicates and store them in a list.

```{r}
#| eval: false

nga <- nga[order(nga$HRname), ]

duplicated_area <- nga$HRname[nga$HRname %in%
                                nga$HRname[duplicated(nga$HRname)]]

duplicated_area
```

![](data2/screenshot%202.jpg)

From the above results, we identified 12 HRnames that are duplicates.

Using the code chunk below, we will find out the index numbers of these duplicated values so that we can update the names subsequently.

```{r}
#| eval: false

which(nga$HRname %in% c("Bassa", "Ifelodun", "Irepodun", "Nasarawa", "Obi", "Surulere"))
```

![](data2/screenshot%203.jpg)

Using the code chunk below, we will access the individual index of the Nigeria data frame and differentiate these 12 HRnames by including their state name (*captured in ADM_1 Name*) e.g. Bassa(Kogi). We will also use the length() function to ensure that all duplicates are eliminated.

```{r}
#| eval: false

nga$HRname[c(92, 93, 303, 304, 354, 355, 518, 519, 545, 546, 692, 693)] <- c("Bassa (Kogi)", "Bassa (Plateau)", "Ifelodun (Kwara)","Ifelodun (Osun)","Irepodun (Kwara)", "Irepodun (Osun)","Nassarawa(Kano)","Nassarawa(Nassarawa)", "Obi (Benue)","Obi(Nasarawa)", "Surulere (Lagos)", "Surulere (Oyo)")

length((nga$HRname[nga$HRname %in%
                     nga$HRname[duplicated(nga$HRname)]]))
```

### 2.2.2 Recoding NA values into string

In the code chunk below, replace_na() of tidyr package is used to recode all the NA values in *status_cle* and *water_te_2* fields into "Unknown".

```{r}
#| eval: false

wp_nga <- read_rds("data2/wp_nga.rds") %>%
  mutate(status_cle = replace_na(status_cle, "Unknown")) %>%
  mutate(water_te_2 = replace_na(water_te_2, "Unknown"))
```

### 2.2.3 Exploratory data analysis (EDA)

In the code chunks below, freq() of funModeling package is used to display the distribution of *status_cle* field in *wp_nga*.

```{r}
#| eval: false

freq(data = wp_nga,
     input = "status_cle")
```

![](data2/screenshot%204.jpg)

### 2.2.4 Extracting functional water point

In the code chunk below, filter() of dplyr is used to select functional water points.

```{r}
#| eval: false

wpt_functional <- wp_nga %>%
  filter(status_cle %in%
           c("Functional",
             "Functional but not in use",
             "Functional but needs repair"))
```

```{r}
#| eval: false

freq(data= wpt_functional,
     input = "status_cle")
```

![](data2/screenshot%205.jpg)

### 2.2.5 Extracting non-functional water point

In the code chunk below, filter() of dplyr is used to select non-functional water points.

```{r}
#| eval: false

wpt_nonfunctional <- wp_nga %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned",
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

```{r}
#| eval: false

freq(data = wpt_nonfunctional,
     input = "status_cle")
```

![](data2/screenshot%206.jpg)

### 2.2.6 Extracting main water point technology

In the code chunks below, unique() and freq() of funModeling package is used to display the types of water technologies (i.e. *water_te_2* field) and their respective distributions in *wp_nga*.

```{r}
#| eval: false

wp_nga <- wp_nga[order(wp_nga$water_te_2), ]

water_tech <- unique(wp_nga$water_te_2)

water_tech
```

![](data2/screenshot%207.jpg)

```{r}
#| eval: false

freq(data = wp_nga,
     input = "water_te_2")
```

![](data2/screenshot%208.jpg)

In the code chunks below, filter() of dplyr is used to select water points whose main technology is hand pumps, and freq() of funModeling package to determine the distribution.

```{r}
#| eval: false

wpt_handpump <- wp_nga %>%
  filter(water_te_2 %in%
           c("Hand Pump",
             "Hand Pump - Afridev",
             "Hand Pump - India Mark II",
             "Hand Pump - India Mark III",
             "Hand Pump - Mono",
             "Hand Pump - Rope Pump"))
```

```{r}
#| eval: false
freq(data = wpt_handpump,
     input = "water_te_2")
```

![](data2/screenshot%209.jpg)

In the code chunks below, filter() of dplyr is used to select water points whose main technology is mechanised pumps, and freq() of funModeling package to determine the distribution.

```{r}
#| eval: false
wpt_mechpump <- wp_nga %>%
  filter(water_te_2 %in%
           c("Mechanized Pump",
             "Mechanized Pump - Diesel",
             "Mechanized Pump - Solar"))
```

```{r}
#| eval: false
freq(data = wpt_mechpump,
     input = "water_te_2")
```

![](data2/screenshot%2010.jpg)

In the code chunks below, filter() of dplyr is used to select water points whose main technology is rope and buckets, as well as the unknowns, and freq() of funModeling package to determine their distributions.

```{r}
#| eval: false
wpt_misc <- wp_nga %>%
  filter(water_te_2 %in%
           c("Rope and Bucket",
             "Unknown"))
```

```{r}
#| eval: false
freq(data = wpt_misc,
     input = "water_te_2")
```

![](data2/screenshot%2011.jpg)

### 2.2.7 Extracting usage capacity

In the code chunks below, filter() of dplyr is used to select usage capacity (i.e. \<1000, \>= 1000), and freq() of funModeling package to determine their distributions.

```{r}
#| eval: false

wpt_usage1000less <- wp_nga %>%
  filter(usage_cap < 1000)

wpt_usage1000more <- wp_nga %>%
  filter(usage_cap >= 1000)
```

```{r}
#| eval: false
freq(data = wp_nga,
     input = "usage_cap")
```

![](data2/screenshot%2016.jpg)

### 2.2.7 Extracting rural water points

In the code chunk below, filter() of dplyr is used to select rural water points, and freq() of funModeling package to determine the distribution.

```{r}
#| eval: false
freq(data = wp_nga,
     input = "is_urban")
```

![](data2/screenshot%2013.jpg)

```{r}
#| eval: false
wpt_rural <- wp_nga %>%
  filter(is_urban == "False")

wpt_urban <- wp_nga %>%
  filter(is_urban == "True")
```

### 2.2.8 Point-in-polygon overlay

Although *wp_nga* sf data frame consists of a field called *#clean_adm2* which by right should provide the LGA name of the water point located, it is always a good practice to be more caution when dealing with data accuracy.

In this section, we are going to use a geoprocessing function (or commonly know as GIS analysis) called **point-in-polygon overlay** to transfer the attribute information in *nga* sf data frame into *wp_sf* data frame.

```{r}
#| eval: false
wp_nga <- st_join(wp_nga, nga)
```

Notice that a new field called HRname has been added into the wp_nga sf data frame as shown below.

![](data2/screenshot.jpg)

In the code chunk below, st_intersects() of sf is used to identify water points located in each Nigerian province; *lengths()* of Base R is used to calculate numbers of water points that fall inside each province, and mutate() of dplyr package is used to derive eight fields, namely: (a) total wpt, (b) wpt functional, (c) wpt non-functional, (d) wpt main tech (i.e. hand pump), (e) wpt main tech (i.e. mech pump), (f) usage capacity \>= 1000, (g) usage capacity \<1000, (h) rural water points.

```{r}
#| eval: false

nga_wp <- nga %>% 
  mutate(`total wpt` = lengths(
    st_intersects(nga, wp_nga))) %>%
  mutate(`wpt functional` = lengths(
    st_intersects(nga, wpt_functional))) %>%
  mutate(`wpt non-functional` = lengths(
    st_intersects(nga, wpt_nonfunctional))) %>%
  mutate(`wpt handpump` = lengths(
    st_intersects(nga, wpt_handpump))) %>%
  mutate(`wpt mechpump` = lengths(
    st_intersects(nga, wpt_mechpump))) %>%
  mutate(`wpt usage1000less` = lengths(
    st_intersects(nga, wpt_usage1000less))) %>%
  mutate(`wpt usage1000more` = lengths(
    st_intersects(nga, wpt_usage1000more))) %>%
  mutate(`wpt rural` = lengths(
    st_intersects(nga, wpt_rural)))
```

### 2.2.9 Saving the analytical data table

In the code chunk below, mutate() of dplyr package is used to drive seven fields, namely pct_functional, pct non-functional, pct wpt_handpump, pct wpt_mechpump, pct wpt_usage1000more, pct qpt_usage1000less and pct wpt_rural.

```{r}
#| eval: false

nga_wp <- nga_wp %>% 
  mutate(`pct_functional` = `wpt functional` / `total wpt`) %>%
  mutate(`pct_non-functional` = `wpt non-functional`/ `total wpt`) %>%
  mutate(`pct_handpump` = `wpt handpump`/ `total wpt`) %>%
  mutate(`pct_mechpump` = `wpt mechpump`/ `total wpt`) %>%
  mutate(`pct_usage1000less` = `wpt usage1000less`/ `total wpt`) %>%
  mutate(`pct_usage1000more` = `wpt usage1000more`/ `total wpt`) %>%
  mutate(`pct_rural` = `wpt rural`/ `total wpt`)
```

Next, write_rds() of readr package is used to save the extracted sf data table into an output file in rds data format, and saved in the data sub-folder.

```{r}
#| eval: false

write_rds(nga_wp, "data2/nga_wp.rds")
```

### 2.2.10 Assigning EPSG code to the simple feature data frame

One of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.

Using the code chunk below, we will examine the current coordinate system of `nga_wp` simple feature data frame by using *st_crs()* of *sf* package.

```{r}
#| eval: false

st_crs(nga_wp)
```

![](data2/screenshot%2014.jpg)

*Observation: Although `the nga_wp`data frame is projected in WGS84 but when we read until the end of the print, it indicates that the EPSG is 4326. This is a wrong EPSG code because the correct EPSG code for WGS84 should be either 26391, 26392, or 26303*

Using the code below, *st_transform()* of **sf** package is used to assign the correct EPSG code (which we will select 26391) to `nga_wp` data frame.

```{r}
#| eval: false

nga_wp26391 <- st_transform(nga_wp,
                            crs = 26391)
```

Using the code chunk below, we will check the CRS again.

```{r}
#| eval: false

st_crs(nga_wp26391)
```

![](data2/screenshot%2015.jpg)

Next, write_rds() of readr package is used to save the extracted sf data table into an output file in rds data format, and saved in the data sub-folder.

```{r}
#| eval: false

write_rds(nga_wp26391, "data2/nga_wp26391.rds")
```

# 3. Exploratory Data Analysis (EDA)

## 3.1 EDA using statistical graphics

In the code chunk below, we plot the distribution of the variables (e.g. Number of water points with hand pumps). Histogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)

```{r}
nga_wp <- read_rds("data2/nga_wp26391.rds")
```

```{r}
wpf <- ggplot(data=nga_wp, 
       aes(x=`wpt functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pcf <- ggplot(data=nga_wp, 
       aes(x=`pct_functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

wpnf <- ggplot(data=nga_wp, 
       aes(x=`wpt non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pcnf <- ggplot(data=nga_wp, 
       aes(x=`pct_non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pchp <- ggplot(data=nga_wp, 
       aes(x=`pct_handpump`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pcmp <- ggplot(data=nga_wp, 
       aes(x=`pct_mechpump`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pcu1l <- ggplot(data=nga_wp, 
       aes(x=`pct_usage1000less`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pcu1m <- ggplot(data=nga_wp, 
       aes(x=`pct_usage1000more`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

pcu <- ggplot(data=nga_wp, 
       aes(x=`pct_rural`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

```{r}
#| fig.width : 10
#| fig.height: 15

ggarrange(wpf, pcf, wpnf, pcnf, pchp, pcmp, pcu1l, pcu1m, pcu, 
          ncol = 2, 
          nrow = 5)
```

## 3.2 EDA using a choropleth map

# 4. Correlation Analysis

Before we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.

In the code chunk below, we will first assign all the NaN values to 0.

```{r}
nga_wp$pct_functional[is.nan(nga_wp$pct_functional)] <- 0
nga_wp$`pct_non-functional`[is.nan(nga_wp$`pct_non-functional`)] <- 0
nga_wp$pct_handpump[is.nan(nga_wp$pct_handpump)] <- 0
nga_wp$pct_mechpump[is.nan(nga_wp$pct_mechpump)] <- 0
nga_wp$pct_usage1000less[is.nan(nga_wp$pct_usage1000less)] <- 0
nga_wp$pct_usage1000more[is.nan(nga_wp$pct_usage1000more)] <- 0
nga_wp$pct_rural[is.nan(nga_wp$pct_rural)] <- 0
```

Using the code chunk below, we will use [*corrplot.mixed()*](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) function of [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) package to visualise and analyse the correlation of the input variables.

```{r}
nga_wp_derived <- nga_wp %>%
  st_set_geometry(NULL) %>%
  select(c(14,15,21:27))
  
head(nga_wp_derived)
```

```{r}
cluster_vars.cor = cor(nga_wp_derived)
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

From the output above, we can observe that there is a high positive correlation (\> 0.8) between pct_handpump and pct_usage1000less, as well as high negative correlation between pct_mechpump and pct_usage1000less. It is noteworthy that there is perfect correlation between pct_mechpump and pct_usage1000more as the correlation value is 1.

# 5. Hierarchy Cluster Analysis

## 5.1 Extracting clustering variables

In the code chunk below, XXX.

```{r}
cluster_vars <- nga_wp %>%
  st_set_geometry(NULL) %>%
  select("HRname", c(14,15,21:27))

head(cluster_vars,10)
```

Using the code chunk below, we will next change the rows by township name instead of row number.

```{r}
row.names(cluster_vars) <- cluster_vars$"HRname"
head(cluster_vars, 10)
```

From the output above, the row number has been replaced with townshop name.

Using the code chunk below, we will delete the "HRname' field.

```{r}
nga_wp_pct <- select(cluster_vars, c(2:10))
head(nga_wp_pct, 10)
```

## 5.2 Data Standardisation

In general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.

### 5.2.1 Min-Max Standardisation

In the code chunk below, *normalize()* of [*heatmaply*](https://cran.r-project.org/web/packages/heatmaply/) package is used to stadardisation the clustering variables by using Min-Max method. The *summary()* is then used to display the summary statistics of the standardised clustering variables.

```{r}
nga_wp_pct.std <- normalize(nga_wp_pct)

summary(nga_wp_pct.std)
```

From the output above, we notice that the values range of the min-max standardised clustering variables are between 0 and 1 now.

### 5.2.2 Z-score standardisation

Z-score standardisation can be performed easily by using [*scale()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/scale) of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method. describe() of [**psych**](https://cran.r-project.org/web/packages/psych/) package is used here because it provides standard deviation.

```{r}
nga_wp_pct.z <- scale(nga_wp_pct)
describe(nga_wp_pct.z)
```

From the output above, the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.

Note: Z-score will not be used here as not all the variables (as visualised from the histograms in Section 3.1) are normally distributed.

## 5.3 Visualising the standardised clustering variables

Beside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.

The code chunks below plot the scaled *wpt functional, wpt non-functional* fields. The remaining variables (e.g. pct_handpump) need not be plotted since their existing values already range from 0 to 1.

```{r}
#| fig-width: 10
#| fig-height: 20

a <- ggplot(data=nga_wp_derived, 
             aes(x= `wpt functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("wpt functional - Raw values without standardisation")

nga_wp_s_df <- as.data.frame(nga_wp_pct.std)
b <- ggplot(data=nga_wp_s_df, 
       aes(x=`wpt functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("wpt functional - Min-Max Standardisation")

c <- ggplot(data=nga_wp_derived, 
             aes(x= `wpt non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("wpt non-functional - Raw values without standardisation")

d <- ggplot(data=nga_wp_s_df, 
       aes(x=`wpt non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("wpt non-functional - Min-Max Standardisation")

e <- ggplot(data=nga_wp_derived, 
             aes(x= `pct_handpump`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("pct_handpump - Raw values without standardisation")

f <- ggplot(data=nga_wp_s_df, 
       aes(x=`pct_handpump`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("pct_handpump - Min-Max Standardisation")

ggarrange(a, b, c, d, e, f, 
          ncol = 2,
          nrow = 4)
```

## 5.4 Computing proximity matrix

Using the code chunk below, we will compute the proximity matrix using dist() of R, method is euclidean method.

```{r}
proxmat <- dist(nga_wp_pct, method = "euclidean")

proxmat
```

## 5.5 Computing hierarchical clustering

Using the code chunk below, we will perform hierarchical cluster analysis using ward.D method of hclust() of R. The hierarchical clustering output is stored in an object of class **hclust** which describes the tree produced by the clustering process.

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

Using the code chunk below, we can then plot the tree using plot() of R Graphics.

```{r}
#| fig-width: 5
#| fig-height: 10
plot(hclust_ward, cex = 0.6)
```

## 5.6 Selecting the optimal clustering algorithm

One of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use [*agnes()*](https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/agnes) function of [**cluster**](https://cran.r-project.org/web/packages/cluster/) package. We can get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).

Using the code chunk below, we will compute the agglomerative coefficients of all hierarchical clustering algorithms.

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(nga_wp_pct, method = x)$ac
}

map_dbl(m, ac)
```

From the output above, we can see that Ward's method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward's method will be used.

## 5.7 Determining optimal clusters

To determine the optimal clusters to retain, we will use one of [three](https://statweb.stanford.edu/~gwalther/gap) commonly used methods to determine the optimal clusters, they are:

-   [Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering))

-   [Average Silhouette Method](https://www.sciencedirect.com/science/article/pii/0377042787901257?via%3Dihub)

-   [Gap Statistic Method](http://www.web.stanford.edu/~hastie/Papers/gap.pdf)

### 5.7.1 Gap statistic method

The **gap statistic** compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.

To compute the gap statistic, [*clusGap()*](https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/clusGap) of [**cluster**](https://cran.r-project.org/web/packages/cluster/) package will be used. Also note that the [*hcut*](https://rpkgs.datanovia.com/factoextra/reference/hcut.html) function used is from [**factoextra**](https://rpkgs.datanovia.com/factoextra/) package.

```{r}
set.seed(12345)
gap_stat <- clusGap(nga_wp_pct, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
print(gap_stat, method = "firstmax")
```

Next, we can visualise the plot by using [*fviz_gap_stat()*](https://rpkgs.datanovia.com/factoextra/reference/fviz_nbclust.html) of [**factoextra**](https://rpkgs.datanovia.com/factoextra/) package.

```{r}
fviz_gap_stat(gap_stat)
```

With reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 4-cluster gives the largest gap statistic and should be the next best cluster to pick.

## 5.8 Interpreting the dendograms

In the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.

The height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.

It's also possible to draw the dendrogram with a border around the selected clusters by using [*rect.hclust()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/rect.hclust.html) of R stats. The argument *border* is used to specify the border colors for the rectangles.

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 4, 
            border = 2:5)
```

## 5.9 Visually-driven hierarchical clustering analysis

In this section, we will perform visually-driven hiearchical clustering analysis by using [*heatmaply*](https://cran.r-project.org/web/packages/heatmaply/) package.

With **heatmaply**, we are able to build both highly interactive cluster heatmap or static cluster heatmap.

### 5.8.1 Transforming the data frame into a matrix

The data was loaded into a data frame, but it has to be a data matrix to make your heatmap. Using the code chunk below, we will transform *nga_wp_pct* data frame into a data matrix.

```{r}
nga_wp_pct_mat <- data.matrix(nga_wp_pct)
```

### 5.8.2 Plotting interactive cluster heatmap using heatmaply()

Using the code chunk below, the [*heatmaply()*](https://talgalili.github.io/heatmaply/reference/heatmaply.html) of [heatmaply](https://talgalili.github.io/heatmaply/) package is used to build an interactive cluster heatmap.

```{r}
#|fig-height: 20

heatmaply(normalize(nga_wp_pct_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 64,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Nigeria by Water Tech indicators",
          xlab = "Water Technolgy Indicators",
          ylab = "Townships of Nigeria"
          )
```

## 5.9 Mapping the clusters formed

With closed examination of the dendragram above, we will retain the 4 clusters. Using the code chunk below, we will derive a 4-cluster model using cutree() of Base R.

```{r}
groups <- as.factor(cutree(hclust_ward, k=4))
```

The output from the code chunk above is called groups. As it is a list object, in order to visualise the clusters, the groups object need to be appended onto the nga_wp sf object.

Using the code chunk below, we will:

-   convert the groups list object into a matrix;

-   append groups matrix onto nga_wp using cbind() to produce an output simple feature object called nga_wp_cluster; and

-   rename as.matrix.groups. field as CLUSTER using rename() of dpylr package

```{r}
nga_wp_cluster <- cbind(nga_wp, as.matrix(groups))%>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

Using the code chunk below, we will next plot the choropleth map showing the cluster formed using qtm() of tmap package.

```{r}
qtm(nga_wp_cluster, "CLUSTER")
```

The choropleth map above reveals the clusters are very fragmented. This is one of the major limitationa when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.

# 6. Spatially Contrained Clustering: Skater Approach

In this section, we will derive spatially constrained cluster by using [*skater()*](https://r-spatial.github.io/spdep/reference/skater.html) method of [**spdep**](https://r-spatial.github.io/spdep/) package.

## 6.1 Converting into SpatialPolygonsDataFrame

First, we need to convert `nga_wp` into SpatialPolygonsDataFrame. This is because SKATER function only support **sp** objects such as SpatialPolygonDataFrame.

The code chunk below uses [*as_Spatial()*](https://r-spatial.github.io/sf/reference/coerce-methods.html) of **sf** package to convert *nga_wp* into a SpatialPolygonDataFrame called *nga_wp_sp*.

```{r}
nga_wp_sp <- as_Spatial(nga_wp)
```

## 6.2 Computing neighbour list

Using the code chunk below, we will use [poly2nd()](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package to compute the neighbours list from polygon list.

```{r}
nga_wp.nb <- poly2nb(nga_wp_sp)
summary(nga_wp.nb)
```

We can plot the neighbours list on nga_wp_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Nigeria state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.

```{r}
#| fig-width: 30
#| fig-height: 30

plot(nga_wp_sp, 
     border=grey(.5))
plot(nga_wp.nb, 
     coordinates(nga_wp_sp), 
     col="blue", 
     add=TRUE)
```

Note that if we plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.

## 6.3 Computing minimum spanning tree

### 6.3.1 Calculating edge costs

Using the code chunk below, we will compute the cost of each edge, using [*nbcosts()*](https://r-spatial.github.io/spdep/reference/nbcosts.html) of **spdep** package. It is the distance between each node. This function compute this distance using a data.frame with observations vector in each node

```{r}
lcosts <- nbcosts(nga_wp.nb, nga_wp_pct)
```

For each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.

Next, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed ***lcosts*** as the weights.

In order to achieve this, [*nb2listw()*](https://r-spatial.github.io/spdep/reference/nb2listw.html) of **spdep** package is used as shown in the code chunk below.

Note that we specify the *style* as **B** to make sure the cost values are not row-standardised.

```{r}
nga_wp.w <- nb2listw(nga_wp.nb, 
                   lcosts, 
                   style="B")
summary(nga_wp.w)
```

## 6.4 Computing minimum spanning tree

Using the code chunk below, we will compute the minimum spanning tree by the mean of the [*mstree()*](https://r-spatial.github.io/spdep/reference/mstree.html) of **spdep** package

```{r}
nga_wp.mst <- mstree(nga_wp.w)
```

After computing the MST, we can check its class and dimension by using the code chunk below.

```{r}
class(nga_wp.mst)
```

```{r}
dim(nga_wp.mst)
```

Note that the dimension is 772 and not 773. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.

Using the code chunk below, we can display the content of *nga_wp.mst* by using *head()* .

```{r}
head(nga_wp.mst)
```

The plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.

```{r}
#| fig-width: 30
#| fig-height: 30

plot(nga_wp_sp, border=gray(.5))
plot.mst(nga_wp.mst, 
         coordinates(nga_wp_sp), 
         col="blue", 
         cex.lab=0.2, 
         cex.circles=0.0005, 
         add=TRUE)
```

## 6.5 Computing spatially constrained clusters using SKATER method

Using the code chunk below, we can compute the spatially constrained cluster using [*skater()*](https://r-spatial.github.io/spdep/reference/skater.html) of **spdep** package.

```{r}
clust4 <- spdep::skater(edges = nga_wp.mst[,1:2], 
                 data = nga_wp_pct, 
                 method = "euclidean", 
                 ncuts = 3)
```

The *skater()* takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to **one less than the number of clusters**. So, the value specified is **not** the number of clusters, but the number of cuts in the graph, one less than the number of clusters. The result of the *skater()* is an object of class **skater**.

Next, we will examine its contents by using the code chunk below.

```{r}
str(clust4)
```

The most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.

We can check the cluster assignment by using the code chunk below.

```{r}
ccs4 <- clust4$groups
ccs4
```

We can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 8, which is also the number of observations in the first cluster.

```{r}
table(ccs4)
```

Lastly, we can also plot the pruned tree that shows the four clusters on top of the townshop area.

```{r}
#| fig-width: 30
#| fig-height: 30

plot(nga_wp_sp, border=gray(.5))
plot(clust4, 
     coordinates(nga_wp_sp), 
     cex.lab=.2,
     groups.colors=c("red","green","blue", "pink"),
     cex.circles=0.0005, 
     add=TRUE)
```

## 6.6 Visualising the clusters in choropleth map

Using the code chunk below, we will plot the newly derived clusters by using SKATER method

```{r}
groups_mat <- as.matrix(clust4$groups)
nga_wp_spatialcluster <- cbind(nga_wp_cluster, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)
qtm(nga_wp_spatialcluster, "SP_CLUSTER")
```

For easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.

```{r}
hclust.map <- qtm(nga_wp_cluster,
                  "CLUSTER") + 
  tm_borders(alpha = 0.5) 

shclust.map <- qtm(nga_wp_spatialcluster,
                   "SP_CLUSTER") + 
  tm_borders(alpha = 0.5) 

tmap_arrange(hclust.map, shclust.map,
             asp=NA, ncol=2)
```

# 7. Spatially Constrained Clustering: ClustGeo Method

In this section, we will use functions provided by **ClustGeo** package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis

## 7.1 Ward-like hierarchical clustering: ClustGeo

ClustGeo package provides function called `hclustgeo()` to perform a typical Ward-like hierarchical clustering just like `hclust()`.

To perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.

```{r}
nongeo_cluster <- hclustgeo(proxmat)
plot(nongeo_cluster, cex = 0.5)
rect.hclust(nongeo_cluster, 
            k = 4, 
            border = 2:5)
```

## 7.1.1 Mapping the clusters formed

Next, we will plot the clusters on a categorical area shaded map by using similar steps in section 5.9.

```{r}
groups <- as.factor(cutree(nongeo_cluster, k=4))
```

```{r}
nga_wp_ngeo_cluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

```{r}
qtm(nga_wp_ngeo_cluster, "CLUSTER")
```

## 7.2 Spatially constrained hierarchical clustering

Using the code chunk below, we will derive the spatial distance matrix using [`st_distance()`](https://r-spatial.github.io/sf/reference/geos_measures.html) of sf package, before performing the spatially constrained hierarchical clustering.

```{r}
dist <- st_distance(nga_wp, nga_wp)
distmat <- as.dist(dist)
```

Notice that `as.dist()` is used to convert the data frame into matrix.

Next, `choicealpha()` will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.

```{r}
cr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=4, graph = TRUE)
```

With reference to the graphs above, in the code chunk below, alpha = 0.2 will be used.

```{r}
clustG <- hclustgeo(proxmat, distmat, alpha = 0.2)
```

Next, `cutree()` is used to derive the cluster object.

```{r}
groups <- as.factor(cutree(clustG, k=4))
```

Using the code chunk below, we will then join back the group list with *nga_wp* polygon feature data frame.

```{r}
nga_wp_Gcluster <- cbind(nga_wp, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

We can now plot the map of the newly delineated spatially constrained clusters.

```{r}
qtm(nga_wp_Gcluster, "CLUSTER")
```

# 8. Visual Interpretation of Cluster

## 8.1 Visualising individual clustering variables

Using the code chunk below, we will reveal the distribution of two clustering variables (i.e wpt functional, wpt non-functional) by cluster.

```{r}
w <- ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = `wpt.functional`)) +
  geom_boxplot()

y <- ggplot(data = nga_wp_ngeo_cluster,
       aes(x = CLUSTER, y = `wpt.non.functional`)) +
  geom_boxplot()

ggarrange(w, y,
          ncol = 2,
          nrow = 1)
```

The boxplots reveal that Cluster X displays the highest mean wpt_functional, while Cluster Y displays the highest mean wpt_non-functional.

## 8.2 Multivariate visualisation

Using the code chunks below, we will display parallel coordinate plots to reveal clustering variables by cluster. using [`ggparcoord()`](https://ggobi.github.io/ggally/reference/ggparcoord.html) of [**GGally**](https://ggobi.github.io/ggally/) package.

```{r}
#| fig-width: 30
#| fig-height: 20

ggparcoord(data = nga_wp_ngeo_cluster, 
           columns = c(14:15, 21:27), 
           scale = "globalminmax",
           alphaLines = 0.2,
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of Water Tech Variables by Cluster") +
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 30))
```
